# Scroll Data Preprocessing

This repository contains data preprocessing scripts for handling scroll dataset images and segmentation masks. The pipeline includes dataset preparation, normalization, augmentation, and model training using **PyTorch Lightning** and **TimeSformer** for temporal segmentation.

## ğŸ“‚ Repository Structure

```
â”œâ”€â”€ data_preprocessing/
â”‚   â”œâ”€â”€ dataset.py          # Custom PyTorch Dataset class for scroll images
â”‚   â”œâ”€â”€ main.py             # Main script for training the segmentation model
â”‚   â”œâ”€â”€ model.py            # Implementation of TimeSformer segmentation model
â”‚   â”œâ”€â”€ preprocessing.py    # Prepares datasets from fragments and segments
â”‚   â”œâ”€â”€ scheduler.py        # Learning rate scheduler with warm-up
â”‚   â”œâ”€â”€ utils.py            # Utility functions for seed setting and directory creation
â”‚   |â”€â”€ config/
â”‚       â”œâ”€â”€ config.yaml         # Configuration file for Hydra
â”‚â”€â”€ setup.py                # Installation script for pip
â”‚â”€â”€ vesuvius.yaml           # Conda environment file
â”‚â”€â”€ README.md               # Project documentation
```

## ğŸ”§ Installation

### Using Conda (Recommended)
To create a Conda environment with all dependencies:

```bash
conda env create -f vesuvius.yaml
conda activate vesuvius
```
Then run the following to use the setup.py file.

```bash
pip install -e .
```

## ğŸš€ Usage

### ğŸ“‚ Expected Data Format

Before running the preprocessing or training scripts, ensure your data is structured as follows:

```
<comp_dataset_path>/  # Root data directory (specified in config.yaml)
â”œâ”€â”€ Fragments/
â”‚   â”œâ”€â”€ Fragment1/
â”‚   â”‚   â”œâ”€â”€ cache/
â”‚   â”‚   â”‚   â”œâ”€â”€ data.zarr/  # Preprocessed fragment data
â”‚   â”œâ”€â”€ Fragment2/
â”‚   â”‚   â”œâ”€â”€ cache/
â”‚   â”‚   â”‚   â”œâ”€â”€ data.zarr/
â”‚   â”œâ”€â”€ ...
â”‚
â”œâ”€â”€ Scroll1/
â”‚   â”œâ”€â”€ segments/
â”‚   â”‚   â”œâ”€â”€ 20230503225234/
â”‚   â”‚   â”‚   â”œâ”€â”€ cache/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ data.zarr/  # Preprocessed segment data
â”‚   â”‚   â”œâ”€â”€ 20230504093154/
â”‚   â”‚   â”‚   â”œâ”€â”€ cache/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ data.zarr/
â”‚   â”‚   â”œâ”€â”€ 20230504094316/
â”‚   â”‚   â”‚   â”œâ”€â”€ cache/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ data.zarr/
â”‚   â”‚   â”œâ”€â”€ ...
â”‚
â”œâ”€â”€ Scroll2/
â”‚   â”œâ”€â”€ segments/
â”‚   â”‚   â”œâ”€â”€ <segment_number>/
â”‚   â”‚   â”‚   â”œâ”€â”€ cache/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ data.zarr/
â”‚   â”‚   â”œâ”€â”€ ...
```

Each `data.zarr/` directory contains processed fragment or segment data. This is the dataset that will be available for download from our submission (more details on where/how to access this will be added later).

#### Using Cached Data
If your dataset is structured exactly as shown above, you do not need to preprocess the data manually. Instead, simply run the training script:

```bash
python data_preprocessing/main.py
```
#### Enabling Cached Data Loading
To skip preprocessing and load cached `.zarr/` files instead, ensure `use_cache` is enabled in config.yaml:

```yaml
comp_dataset_path: "/path/to/your/data"  # Update this path to your dataset location
use_cache: True  # Load preprocessed data instead of recomputing
```

This ensures that main.py will automatically read from the existing `cache/data.zarr/` directories, speeding up the pipeline.

### 1ï¸âƒ£ Dataset Preparation
Before training, preprocess the dataset using:

```bash
python data_preprocessing/preprocessing.py
```

This script processes image fragments and segmentation masks, splitting them into **train, validation, and test** sets.

#### Customizing Preprocessing Parameters
You can modify dataset parameters in config/config.yaml before running the script. Some key parameters you might want to tweak:

```yaml
# Fragments to process
fragment_ids: [1, 2, 3]  # List of fragment numbers to include

# Specify a single fragment for validation
validation_fragment_id: 1  # Set to "-1" to disable validation

# Segments to process
scrolls:
  - scroll_id: 2
    num_segments: -1  # "-1" means process all segments from this scroll
  # - scroll_id: 3
  #   num_segments: 10  # Reads 10 random segments from this scroll

# Validation segment frequency
validation_segments_mod: 5  # Every 5th segment is used for validation (set "-1" to disable)

```

- `fragment_ids`: List of fragment numbers to process.
- `validation_fragment_id`: Select a single fragment for validation (-1 disables validation).
- `scrolls`: Specifies which scrolls to read and how many random segments to include.
- `num_segments`:
    - **-1** â†’ Read all segments from this scroll
    - **n** â†’ Select n random segments from this scroll (Replace **n** with an actual value)
- `validation_segments_mod`: Controls how often a segment is assigned to validation.


ğŸš¨ Important: During data collection, no explicit validation data was specified so by default, everything is saved as training data. If needed, adjust `validation_fragment_id` and `validation_segments_mod` to designate validation samples.


### 2ï¸âƒ£ Training the Model
To train the segmentation model, run:

```bash
python data_preprocessing/main.py
```

This will:
- Load the dataset using `ScrollDataset`
- Train the `TimeSformerModel` with **PyTorch Lightning**
- Log training metrics and model checkpoints using **Weights & Biases (wandb)**

### 3ï¸âƒ£ Model Architecture
The model is based on **TimeSformer**, a **video transformer** adapted for **scroll image segmentation**. The model structure is implemented in `data_preprocessing/model.py`.

## ğŸ—ï¸ Code Components

### `data_preprocessing/dataset.py`
Defines `ScrollDataset`, a custom PyTorch Dataset class that:
- Loads image and mask patches
- Applies **temporal augmentations**
- Returns training/validation data

### `data_preprocessing/model.py`
Implements `TimeSformerModel`, a **spatiotemporal transformer** that:
- Uses `TimeSformer` for feature extraction
- Optimizes with **Dice Loss + BCE Loss**
- Implements **gradient clipping** for stability

### `data_preprocessing/preprocessing.py`
Handles dataset preparation:
- Loads images/masks from fragments & segments
- Applies **tiling** and **augmentation**
- Saves preprocessed data as NumPy arrays

### `data_preprocessing/main.py`
Main script that:
- Loads configuration via Hydra
- Initializes dataset and dataloaders
- Runs the training loop using **PyTorch Lightning**
- Logs to **Weights & Biases (wandb)**

### `data_preprocessing/utils.py`
Helper functions for:
- Setting **random seed** for reproducibility
- Creating **directories** dynamically

### `data_preprocessing/scheduler.py`
Implements a **warm-up learning rate scheduler** to stabilize training.

## ğŸ“ Configuration
The pipeline is configured using Hydra (`config/config.yaml`). Modify hyperparameters such as:

```yaml
train_batch_size: 8
valid_batch_size: 4
epochs: 50
lr: 0.0001
tile_size: 256
stride: 128
```

## ğŸ“Š Logging & Visualization
Training logs are stored in **Weights & Biases (wandb)**. Ensure `wandb` is properly configured:

```bash
wandb login
```

To visualize results:

```bash
wandb online
```

## ğŸ“œ License
This project is licensed under the **MIT License**.

## ğŸ‘¥ Contributors
- **Aryan Gulati**
- **Aditya Kumar**
- **Jaiv Doshi**
- **Leslie Moreno**
